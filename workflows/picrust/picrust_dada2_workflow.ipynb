{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PICRUSt with de novo Variants Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chenghao Zhu\n",
    "#### 2018/04/28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This workflow uses the DADA2(or any other de novo clustering algorithm) output to run the PICRUSt function prediction.\n",
    "* This workflow was created by the Langille lab. If you want to know more detail, please visit their github tutorial page\n",
    "    https://github.com/LangilleLab/microbiome_helper/wiki/PICRUSt-Tutorial-with-de-novo-Variants#add-metadata-to-ko-table \n",
    "* This workflow requires the sequence alignment tool and the fasttree software in QIIME2. So **MAKE SURE** that you activate the qiime2 enviroment before you start this jupyter notebook. The qiime2 version that I used when I wrote thsi workflow is qiime2-2018.2, although the 2018.4 version is already released."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create New Reference Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!biom convert \\\n",
    "    -i dada2_out/feature_table_rarefied.tsv \\\n",
    "    -o dada2_out/feature_table.biom \\\n",
    "    --to-json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!biom add-metadata \\\n",
    "    -i dada2_out/feature_table.biom \\\n",
    "    -o dada2_out/feature_table_taxa.biom \\\n",
    "    --observation-metadata-fp dada2_out/taxonomy_for_biom.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat dada2_out/rep_seqs.fasta img_gg_starting_files/gg_13_5_img_subset.fasta > study_seqs_gg_13_5_img_subset.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qiime tools import \\\n",
    "    --input-path study_seqs_gg_13_5_img_subset.fasta \\\n",
    "    --output-path rep_seqs_gg_img.qza \\\n",
    "    --type 'FeatureData[Sequence]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qiime alignment mafft \\\n",
    "    --i-sequences rep_seqs_gg_img.qza \\\n",
    "    --o-alignment rep_seqs_gg_img_aligned.qza "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qiime alignment mask \\\n",
    "    --i-alignment rep_seqs_gg_img_aligned.qza \\\n",
    "    --o-masked-alignment rep_seqs_gg_img_masked.qza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qiime phylogeny fasttree \\\n",
    "    --i-alignment rep_seqs_gg_img_masked.qza \\\n",
    "    --o-tree unrooted-tree.qza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qiime tools export \\\n",
    "    unrooted-tree.qza \\\n",
    "    --output-dir ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PICRUSt genome prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by formatting input tree and trait table. The below commands perform a few different checks of the input files and prepares them for the ASR step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!format_tree_and_trait_table.py \\\n",
    "    -t tree.nwk \\\n",
    "    -i img_gg_starting_files/gg_13_5_img_16S_counts.txt \\\n",
    "    -o format/16S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!format_tree_and_trait_table.py \\\n",
    "    -t tree.nwk \\\n",
    "    -i img_gg_starting_files/img_400_ko.tab \\\n",
    "    -o format/KO -m img_gg_starting_files/gg_13_5_img_fixed.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run ancestral state reconstruction steps for 16S rRNA gene counts to get estimates for every internal node in the tree. The default method is phylogenetic independent contrasts although there are other methods available as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ancestral_state_reconstruction.py \\\n",
    "    -i format/16S/trait_table.tab \\\n",
    "    -t format/16S/pruned_tree.newick \\\n",
    "    -o asr/16S_asr_counts.tab \\\n",
    "    -c asr/asr_ci_16S.tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the trait predictions for all internal nodes we can extend these 16S counts predictions to the tips of the tree (i.e. our study sequences of interest). Note that the ASR files for the KEGG orthologs have been pre-calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!predict_traits.py \\\n",
    "    -i format/16S/trait_table.tab \\\n",
    "    -t format/16S/reference_tree.newick \\\n",
    "    -r asr/16S_asr_counts.tab -o predicted/16S_precalculated.tab \\\n",
    "    -a -c asr/asr_ci_16S.tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could also run this command to run ASR for the KO table. These commands can take > 30 minutes so we have made the output files of predict_traits.py available in img_gg_starting_files/precalc_predict if you want to skip these commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ancestral_state_reconstruction.py \\\n",
    "    -i format/KO/trait_table.tab \\\n",
    "    -t format/KO/pruned_tree.newick \\\n",
    "    -o asr/KO_asr_counts.tab \\\n",
    "    -c asr/asr_ci_KO.tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!predict_traits.py \\\n",
    "    -i format/KO/trait_table.tab \\\n",
    "    -t format/KO/reference_tree.newick \\\n",
    "    -r asr/KO_asr_counts.tab \\\n",
    "    -o predicted/KO_precalculated.tab \\\n",
    "    -a -c asr/asr_ci_KO.tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of these commands is the table of trait counts across study and reference variants for both 16S copy number and KOs. Since there is variability in the alignment step it is likely your output will differ at least slightly from the results shown below. You can use our pre-calculated predictions if you want to re-generate the below plots, which are in img_gg_starting_files/precalc_predict. If you want to use the previously generated predicted tables for the below commands then you should first run this command to overwrite the tables in predicted/: cp img_gg_starting_files/precalc_predict/* predicted/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add metadata to KO table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to add the metadata to the KEGG prediction table before proceeding. For this dataset this can easily be done with the below commands (the echo command is just adding a newline to the end of the trait table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"\" >> predicted/KO_precalculated.tab\n",
    "cat img_gg_starting_files/metadata/precalc_meta >> predicted/KO_precalculated.tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions per sample based on the abundance of each variant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the predicted trait abundances per variant (i.e. for their predicted genome) we can get the predicted trait abundances for each sample (i.e. the predicted metagenome). The first step in this process is to normalize the variant abundances by the predicted 16S copy number. This is important so that the abundances of gene families and other functions are comparable in downstream steps.\n",
    "\n",
    "Note that the precalculated trait tables that we generated above are specified with the -c option in the below commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!normalize_by_copy_number.py \\\n",
    "    -i dada2_out/feature_table_taxa.biom \\\n",
    "    -c predicted/16S_precalculated.tab \\\n",
    "    -o seqtab_tax_rarified_norm.biom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the variant table is normalized by 16S copy number we can determine the predicted number functions in each sample. Essentially this command multiplies each variant's normalized abundance by the abundance of each function in the precalculated table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!predict_metagenomes.py \\\n",
    "    -i seqtab_tax_rarified_norm.biom \\\n",
    "    -c predicted/KO_precalculated.tab \\\n",
    "    -o seqtab_tax_rarified_norm_ko.biom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above command generated predicted metagenomes for KEGG orthologs (i.e. the gene families). However, often we are interested in more readily interpretable categories like pathways. To collapse the KEGG orthologs to KEGG pathways the below command can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!categorize_by_function.py \\\n",
    "    -i seqtab_tax_rarified_norm_ko.biom \\\n",
    "    -o seqtab_tax_rarified_norm_ko_l3.biom \\\n",
    "    -c KEGG_Pathways \\\n",
    "    -l 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!biom head -i seqtab_tax_rarified_norm_ko_l2.biom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!biom convert \\\n",
    "    -i seqtab_tax_rarified_norm_ko_l1.biom \\\n",
    "    -o seqtab_tax_rarified_norm_ko_l1.tsv \\\n",
    "    --to-tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head seqtab_tax_rarified_norm_ko_l1.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakdown of Taxonomic Contributions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although predicted metagenomes are useful often users want to know which taxa are actually conferring specific functions. To this end the below command will output a textfile that states what abundance of a function is being conferred by a given variant (and their taxonomic assignment). The below command will output these predicted contributions for two KEGG orthologs: K08602 and K03699."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!metagenome_contributions.py \\\n",
    "    -i seqtab_tax_rarified_norm.biom \\\n",
    "    -l K14203,K11038,K14188,K01315,K01401,K14200,K14201,K14202,K14204,K14205,K03367,K03740,K03739,K11632,K11631,K14198,K14199,K14194,K14195,K14196,K14197,K14192,K14193,K11041,K11040,K11043 \\\n",
    "    -o metagenome_contributions.txt \\\n",
    "    -c predicted/KO_precalculated.tab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3]",
   "language": "python",
   "name": "conda-env-miniconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
